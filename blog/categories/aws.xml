<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title><![CDATA[Tech.Semicolon]]></title>
    <link href="https://techsemicolon.github.io/blog/categories/aws.xml" rel="self"/>
    <link href="https://techsemicolon.github.io/"/>
    <updated>2019-10-21T21:20:45+00:00</updated>
    <id>https://techsemicolon.github.io/</id>
        <generator uri="http://sculpin.io/">Sculpin</generator>
            <entry>
            <title type="html"><![CDATA[A complete setup guide for OpenVPN on AWS with free CertBot SSL]]></title>
            <link href="https://techsemicolon.github.io/blog/2019/10/19/complete-setup-guide-for-openvpn-on-aws-with-certbot-ssl/"/>
            <updated>2019-10-19T00:00:00+00:00</updated>
            <id>https://techsemicolon.github.io/blog/2019/10/19/complete-setup-guide-for-openvpn-on-aws-with-certbot-ssl/</id>
            <content type="html"><![CDATA[<p>OpenVPN is a commercial VPN solutions service to secure your data communications. You can use this in number of ways like hiding your internet identity, remote access to company, inside IoT security and many more. My most favorite use of OpenVPN is to use it as SSH whitelisting, so you can SSH to your server instances only when you are connected to a certain VPN.</p>

<p>Remember, OpenVPN service is not free, but it's cost is very affordable and reasonable for a personal as well as corporate setup!</p>

<h3 id="overview-of-aws-setup-%3A">Overview of AWS setup :</h3>

<p>When you spin up an EC2 instance on AWS, you can either choose from vanilla instance AMIs like basic centos or ubuntu 16.x etc. OR you can choose from pre-baked marketplace AMIs. Services like OpenVPN use marketplace AMIs to provide their pre-baked instances which are ready to use.</p>

<p>But wait.. It is not that plug and play. Setting up OpenVPN can be tricky specially when you do not know the sequence of steps and some little tricks. But, we have got you covered.</p>

<p>We will be also dealing with the common problem of untrusted SSL certificate error and install a free CertBot SSL to make your OpenVPN server full proof. Let's get started!</p>

<h3 id="step-1---spinning-up-the-ec2-server-%3A">Step 1 - Spinning up the EC2 server :</h3>

<ul>
<li>Login to your AWS Console and go to the region you want yout OpenVPN instance to be in</li>
<li>Select EC2 service and click on <code>Launch</code> to spin up a new instance</li>
<li>The EC2 launch wizard will be shown, where click on <code>AWS Marketplace</code> on left</li>
<li>Now search for <code>openvpn</code> and press <code>enter</code></li>
<li>It will show number of official OpenVPN marketplace AMIs which are different in the number of connected devices. I will strongly recommend if you are doing it for the first time, choose the first one which will give you 2 concurrent devices to start with. You can anytime purchase a new license for extending number of users.</li>
</ul>

<p><img src="/images/openvpn-guide/choose-ami.png" alt="alt text1" /></p>

<ul>
<li>Now click on <code>select</code> when you have choosen your AMI</li>
<li>You will be prompted with OpenVPN service cost for each instance type you spin up. This will be added to your AWS billing. I would always choose <code>t2.micro</code> instance type as OpenVPN server does not need much memory to perform it's operations.</li>
</ul>

<p><img src="/images/openvpn-guide/cost.png" alt="alt text1" /></p>

<ul>
<li>Click on <code>continue</code> and choose instance type as <code>t2.micro</code></li>
<li>Click on <code>Next: Configure Instance Details</code></li>
<li>This is an important step. Make sure you choose your VPC if you have one and choose it's public subnet. If you do not have custom VPC and subnets, leave these settings as is. Make sure that its a public subnet as OpenVPN instance should be in a public subnet so it is accessible via web directly.</li>
<li>Click on <code>Next: Add Storage</code></li>
<li>Here you need to make sure the instance volume is encrypted. Otherwise you will get warning like <code>Volume (/dev/sda1) needs to be encrypted as encryption is enabled by default.</code> Click on <code>Encryption</code> dropdown and choose a KMS key which will encrypt your volume. Also make sure your instance volume type is <code>General Purpoise SSD (gp2)</code>. Sometimes it changes to <code>Magnetic (standard)</code> when you enable volume encryption</li>
<li>Click on <code>Next: Add Tags</code> and add the tags you need for this instance</li>
<li>Click on <code>Next: Configure Security Group</code></li>
<li>You need to select <code>Create a new security group</code>. Add security group name as <code>OpenVPN server SG</code>. Wait.. Hey, AWS already has filled in the group rules for you, thats awesome... isn't it?</li>
</ul>

<p><img src="/images/openvpn-guide/sg.png" alt="alt text1" /></p>

<ul>
<li>Click on <code>Review and Launch</code></li>
<li>Verify the details once in this final summary screen and click on <code>Launch</code></li>
<li>It will ask you to select a <code>key pair</code> create a new one as <code>OpenVPN-key-pair</code> and download it.</li>
<li>Now finally.. Click on <code>Launch Instances</code></li>
</ul>

<p>You are done with launching the instance.. Yassssss!! Above steps will launch your new server.</p>

<h3 id="step-2---assigning-elastic-ip-and-domain-%3A">Step 2 - Assigning elastic IP and domain :</h3>

<p>When your instance is up and running, you will see it's public IP given by AWS automatically. However, once you reboot this instance anytime, this IP will change. We do not want that. So we will associate an elastic IP to this instance so it stays no matter if the instance is stopped or rebooted.</p>

<ul>
<li>Select EC2 service from the same region where you have the OpenVPN instance</li>
<li>Click on <code>Elastic IPs</code></li>
<li>Click on <code>Allocate new address</code> and select <code>Allocate</code></li>
<li>Now you will see a new elasic IP in the list which is not associated with any instance</li>
<li>Select that IP and in the actions dropdown choose <code>Associate Address</code></li>
<li>You will see a new association form, keep resource type as <code>Instance</code> and select your new OpenVPN instance from the instance dropdown</li>
<li>Save the association</li>
<li>Now of you go back to the instance and see it's public IP, you will see the new elastic IP as its public IP.</li>
</ul>

<p>Now, you can associate a domain to this new public IP or you can keep as it is. It depends on your preference but I would recommend having a domain like <code>vpn.yourdomain.com</code> to access this server.</p>

<p>If you choose to have a domain, then this is the time when you need to point the A record of your domain to the new elastic public IP. For the consistency in remaining article, we are going to use <code>vpn.yourdomain.com</code>.</p>

<h3 id="step-3-%3A-initializing-up-the-openvpn-basic-settings-%3A">Step 3 : Initializing up the OpenVPN basic settings :</h3>

<p>Now, you will not be able to access openVPN directly. This is because you are yet to initiate the basic settings. For that, we need to ssh into the server.</p>

<ul>
<li>Use the key pair file <code>OpenVPN-key-pair.pem</code> to ssh into the instance. As in the security group port <code>22</code> is open for everyone with value <code>0.0.0.0/0</code>, you would be able to SSH to your instance from anywhere. (We will change that after the setup is completed)</li>
<li>Use ssh username as <code>openvpnas</code> as this comes default with the OpenVPN marketplace AMI</li>
<li>Once you login to the instance, you will see a setup wizard and it will ask you to agree to the terms and conditions</li>
<li>Now it will ask number of settings to you :</li>
</ul>

<pre><code class="bash">openvpnas@openvpnas2:# 

Welcome to OpenVPN Access Server Appliance 2.7.5

  System information as of Sat Oct 19 12:24:42 UTC 2019

  System load:  0.95              Processes:           98
  Usage of /:   26.7% of 7.69GB   Users logged in:     0
  Memory usage: 18%               IP address for eth0: 172.32.1.87
  Swap usage:   0%


          OpenVPN Access Server
          Initial Configuration Tool
------------------------------------------------------
OpenVPN Access Server End User License Agreement (OpenVPN-AS EULA)

    1. Copyright Notice: OpenVPN Access Server License;
       Copyright (c) 2009-2019 OpenVPN Inc. All rights reserved.
       "OpenVPN" is a trademark of OpenVPN Inc.
    2. Redistribution of OpenVPN Access Server binary forms and related documents,
       are permitted provided that redistributions of OpenVPN Access Server binary
       forms and related documents reproduce the above copyright notice as well as
       a complete copy of this EULA.
    3. You agree not to reverse engineer, decompile, disassemble, modify,
       translate, make any attempt to discover the source code of this software,
       or create derivative works from this software.
    4. The OpenVPN Access Server is bundled with other open source software
       components, some of which fall under different licenses. By using OpenVPN
       or any of the bundled components, you agree to be bound by the conditions
       of the license for each respective component. For more information, you can
       find our complete EULA (End-User License Agreement) on our website
       (http://openvpn.net), and a copy of the EULA is also distributed with the
       Access Server in the file /usr/local/openvpn_as/license.txt.
    5. This software is provided "as is" and any expressed or implied warranties,
       including, but not limited to, the implied warranties of merchantability
       and fitness for a particular purpose are disclaimed. In no event shall
       OpenVPN Inc. be liable for any direct, indirect, incidental,
       special, exemplary, or consequential damages (including, but not limited
       to, procurement of substitute goods or services; loss of use, data, or
       profits; or business interruption) however caused and on any theory of
       liability, whether in contract, strict liability, or tort (including
       negligence or otherwise) arising in any way out of the use of this
       software, even if advised of the possibility of such damage.
    6. OpenVPN Inc. is the sole distributor of OpenVPN Access Server
       licenses. This agreement and licenses granted by it may not be assigned,
       sublicensed, or otherwise transferred by licensee without prior written
       consent of OpenVPN Inc. Any licenses violating this provision
       will be subject to revocation and deactivation, and will not be eligible
       for refunds.
    7. A purchased license entitles you to use this software for the duration of
       time denoted on your license key on any one (1) particular device, up to
       the concurrent user limit specified by your license. Multiple license keys
       may be activated to achieve a desired concurrency limit on this given
       device. Unless otherwise prearranged with OpenVPN Inc.,
       concurrency counts on license keys are not to be divided for use amongst
       multiple devices. Upon activation of the first purchased license key in
       this software, you agree to forego any free licenses or keys that were
       given to you for demonstration purposes, and as such, the free licenses
       will not appear after the activation of a purchased key. You are
       responsible for the timely activation of these licenses on your desired
       server of choice. Refunds on purchased license keys are only possible
       within 30 days of purchase of license key, and then only if the license key
       has not already been activated on a system. To request a refund, contact us
       through our support ticket system using the account you have used to
       purchase the license key. Exceptions to this policy may be given for
       machines under failover mode, and when the feature is used as directed in
       the OpenVPN Access Server user manual. In these circumstances, a user is
       granted one (1) license key (per original license key) for use solely on
       failover purposes free of charge. Other failover and/or load balancing use
       cases will not be eligible for this exception, and a separate license key
       would have to be acquired to satisfy the licensing requirements. To request
       a license exception, please file a support ticket in the OpenVPN Access
       Server ticketing system. A staff member will be responsible for determining
       exception eligibility, and we reserve the right to decline any requests not
       meeting our eligibility criteria, or requests which we believe may be
       fraudulent in nature.
    8. Activating a license key ties it to the specific hardware/software
       combination that it was activated on, and activated license keys are
       nontransferable. Substantial software and/or hardware changes may
       invalidate an activated license. In case of substantial software and/or
       hardware changes, caused by for example, but not limited to failure and
       subsequent repair or alterations of (virtualized) hardware/software, our
       software product will automatically attempt to contact our online licensing
       systems to renegotiate the licensing state. On any given license key, you
       are limited to three (3) automatic renegotiations within the license key
       lifetime. After these renegotiations are exhausted, the license key is
       considered invalid, and the activation state will be locked to the last
       valid system configuration it was activated on. OpenVPN Inc.reserves the
       right to grant exceptions to this policy for license holders under
       extenuating circumstances, and such exceptions can be requested through a
       ticket via the OpenVPN Access Server ticketing system.
    9. Once an activated license key expires or becomes invalid, the concurrency
       limit on our software product will decrease by the amount of concurrent
       connections previously granted by the license key. If all of your purchased
       license key(s) have expired, the product will revert to demonstration mode,
       which allows a maximum of two (2) concurrent users to be connected to your
       server. Prior to your license expiration date(s), OpenVPN Inc. will attempt
       to remind you to renew your license(s) by sending periodic email messages
       to the licensee email address on record. You are solely responsible for
       the timely renewal of your license key(s) prior to their expiration if
       continued operation is expected after the license expiration date(s).
       OpenVPN Inc. will not be responsible for any misdirected and/or undeliverable
       email messages, nor does it have an obligation to contact you regarding
       your expiring license keys.
   10. Any valid license key holder is entitled to use our ticketing system for
       support questions or issues specifically related to the OpenVPN Access
       Server product. To file a ticket, go to our website at http://openvpn.net/
       and sign in using the account that was registered and used to purchase the
       license key(s). You can then access the support ticket system through our
       website and submit a support ticket. Tickets filed in the ticketing system
       are answered on a best-effort basis. OpenVPN Inc. staff
       reserve the right to limit responses to users of our demo / expired
       licenses, as well as requests that substantively deviate from the OpenVPN
       Access Server product line. Tickets related to the open source version of
       OpenVPN will not be handled here.
   11. Purchasing a license key does not entitle you to any special rights or
       privileges, except the ones explicitly outlined in this user agreement.
       Unless otherwise arranged prior to your purchase with OpenVPN,
       Inc., software maintenance costs and terms are subject to change after your
       initial purchase without notice. In case of price decreases or special
       promotions, OpenVPN Inc. will not retrospectively apply
       credits or price adjustments toward any licenses that have already been
       issued. Furthermore, no discounts will be given for license maintenance
       renewals unless this is specified in your contract with OpenVPN Inc.

Please enter 'yes' to indicate your agreement [no]: yes

Once you provide a few initial configuration settings,
OpenVPN Access Server can be configured by accessing
its Admin Web UI using your Web browser.

Will this be the primary Access Server node?
(enter 'no' to configure as a backup or standby node)
&gt; Press ENTER for default [yes]: yes

Please specify the network interface and IP address to be
used by the Admin Web UI:
(1) all interfaces: 0.0.0.0
(2) eth0: 172.31.16.206
Please enter the option number from the list above (1-2).
&gt; Press Enter for default [2]: 1

Please specify the port number for the Admin Web UI.
&gt; Press ENTER for default [943]: 943

Please specify the TCP port number for the OpenVPN Daemon
&gt; Press ENTER for default [443]: 443

Should client traffic be routed by default through the VPN?
&gt; Press ENTER for default [yes]: yes

Should client DNS traffic be routed by default through the VPN?
&gt; Press ENTER for default [yes]: yes

Use local authentication via internal DB?
&gt; Press ENTER for default [yes]: yes

Private subnets detected: ['172.31.0.0/16']

Should private subnets be accessible to clients by default?
&gt; Press ENTER for EC2 default [yes]: yes

To initially login to the Admin Web UI, you must use a
username and password that successfully authenticates you
with the host UNIX system (you can later modify the settings
so that RADIUS or LDAP is used for authentication instead).

You can login to the Admin Web UI as "openvpn" or specify
a different user account to use for this purpose.

Do you wish to login to the Admin UI as "openvpn"?
&gt; Press ENTER for default [yes]: yes

&gt; Please specify your OpenVPN-AS license key (or leave blank to specify later):

Initializing OpenVPN...
Adding new user login...
useradd -s /sbin/nologin "openvpn"
Writing as configuration file...
Perform sa init...
Wiping any previous userdb...
Creating default profile...
Modifying default profile...
Adding new user to userdb...
Modifying new user as superuser in userdb...
Getting hostname...
Hostname: openvpnserver
Preparing web certificates...
Getting web user account...
Adding web group account...
Adding web group...
Adjusting license directory ownership...
Initializing confdb...
Generating init scripts...
Generating PAM config...
Generating init scripts auto command...
Starting openvpnas...

NOTE: Your system clock must be correct for OpenVPN Access Server
to perform correctly.  Please ensure that your time and date
are correct on this system.

Initial Configuration Complete!

You can now continue configuring OpenVPN Access Server by
directing your Web browser to this URL:

https://x.x.x.x:943/admin
Login as "openvpn" with the same password used to authenticate
to this UNIX host.

During normal operation, OpenVPN AS can be accessed via these URLs:
Admin  UI: https://x.x.x.x:943/admin
Client UI: https://x.x.x.x:943/

See the Release Notes for this release at:
   https://openvpn.net/vpn-server-resources/release-notes/
</code></pre>

<ul>
<li>Now you we need a password to login first time as an admin. For that run command</li>
</ul>

<pre><code>openvpnas@openvpnas2:~$ sudo passwd openvpn
Enter new UNIX password:
Retype new UNIX password:
passwd: password updated successfully
openvpnas@openvpnas2:~$
</code></pre>

<p>You are done with basic setup, we can now proceed with the web UI for further settings.</p>

<h3 id="step-4-%3A-accessing-openvpn-web-ui-%3A">Step 4 : Accessing OpenVPN Web UI :</h3>

<p>Now we will access the OpenVPN Web UI using the elastic IP with url https://x.x.x.x:943/admin where <code>x.x.x.x</code> is your elasic IP. You might be thinking that we have <code>vpn.yourdomain.com</code> setup so why are we using the elastic IP? We will get back to it shortly but for the first time we will need to use the IP.</p>

<ul>
<li>Visit https://x.x.x.x:943/admin which will say that it is insecure, click on advanced and proceed to visit the website</li>
</ul>

<p><img src="/images/openvpn-guide/admin-login.png" alt="alt text1" /></p>

<ul>
<li>Login with the username <code>openvpn</code> and the admin password you set earlier</li>
<li>Once you login for the first time, you will see a lisence agreement which you select <code>agree</code></li>
</ul>

<p><img src="/images/openvpn-guide/agree.png" alt="alt text1" /></p>

<ul>
<li>Now you will see a nice web UI as below :</li>
</ul>

<p><img src="/images/openvpn-guide/dashboard.png" alt="alt text1" /></p>

<ul>
<li>Go to <code>Configuration &gt; Network Settings</code> on the left hand side menu</li>
<li>You will see a setting <code>Hostname or IP Address</code>. Here we will now enter <code>vpn.yourdomain.com</code></li>
<li>Now click on <code>Save Settings</code></li>
<li>Now click on <code>Update running server</code></li>
</ul>

<p>Now we have the domain set up. You can open another tab and visit <code>https://vpn.yourdomain.com:943/admin</code> and it will work now!</p>

<h3 id="step-5-%3A-having-a-valid-ssl-%3A">Step 5 : Having a valid SSL :</h3>

<p>You must have observed that the SSL comes with the OpenVPN server is not trusted by browsers. So we will have a new CertBot SSL which will not show SSL warnings and errors.</p>

<ul>
<li>SSH to the openvpn server again</li>
<li>Type following commands to install certbot</li>
</ul>

<pre><code class="bash">sudo apt-get update
sudo apt-get install software-properties-common
sudo add-apt-repository universe
sudo add-apt-repository ppa:certbot/certbot
sudo apt-get update
sudo apt-get install -y certbot
</code></pre>

<p>Now we need to open port 80 <code>temporarily</code> on the security group of our OpenVPN server so that Certbot can verify that the server and domain. Certbot will temporarily spin up a webserver on our openVPN machine for the same.
- Go to AWS console and choose our OpenVPN server security group <code>OpenVPN server SG</code>
- In the inbound rules, add HTTP 80 rule with source <code>0.0.0.0/0, ::/0</code> to access tempoarary port 80 traffic</p>

<p>Now we can run Certbot</p>

<ul>
<li>SSH to the openvpn server again</li>
<li>Type following commands to request certbot certificate</li>
</ul>

<pre><code class="bash">sudo certbot certonly --standalone
</code></pre>

<p>It will ask you number of questions and then a domain name. Enter <code>vpn.yourdomain.com</code> and it will verify it using temporary web server on port 80.</p>

<p>Below is the output :</p>

<pre><code>openvpnas@openvpnas2:~$ sudo certbot certonly --standalone
Saving debug log to /var/log/letsencrypt/letsencrypt.log
Plugins selected: Authenticator standalone, Installer None
Enter email address (used for urgent renewal and security notices) (Enter 'c' to
cancel): support@yourdomain.com

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Please read the Terms of Service at
https://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf. You must
agree in order to register with the ACME server at
https://acme-v02.api.letsencrypt.org/directory
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
(A)gree/(C)ancel: A

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Would you be willing to share your email address with the Electronic Frontier
Foundation, a founding partner of the Let's Encrypt project and the non-profit
organization that develops Certbot? We'd like to send you email about our work
encrypting the web, EFF news, campaigns, and ways to support digital freedom.
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
(Y)es/(N)o: N
Please enter in your domain name(s) (comma and/or space separated)  (Enter 'c'
to cancel): vpn.yourdoman.com
Obtaining a new certificate
Performing the following challenges:
http-01 challenge for vpn.yourdoman.com
Waiting for verification...
Cleaning up challenges

IMPORTANT NOTES:
 - Congratulations! Your certificate and chain have been saved at:
   /etc/letsencrypt/live/vpn.youdomain.com/fullchain.pem
   Your key file has been saved at:
   /etc/letsencrypt/live/vpn.youdomain.com/privkey.pem
   Your cert will expire on 2020-01-14. To obtain a new or tweaked
   version of this certificate in the future, simply run certbot
   again. To non-interactively renew *all* of your certificates, run
   "certbot renew"
 - If you like Certbot, please consider supporting our work by:
</code></pre>

<p>Now we are concerned with 2 files : <code>privkey.pem</code> and <code>fullchain.pem</code>. But first, go back to the security group and remove the rule for <code>HTTP port 80</code> as we do not need it anymore!</p>

<p>Now we will view contents of these files and copy them locally. You can use following commands to show their text content, you need to manually copy them and make new files locally with same name and paste the respective contents.</p>

<pre><code class="bash"># Make sure you replace vpn.youdomain.com with your expected domain or ip
cat /etc/letsencrypt/live/vpn.youdomain.com/fullchain.pem
cat /etc/letsencrypt/live/vpn.youdomain.com/privkey.pem
</code></pre>

<p>Final step is to update these certificates on OpenVPN web UI. 
- Visit <code>https://vpn.yourdomain.com:943/admin</code> and login with the admin credentials used earlier
- Go to <code>Configuration &gt; Web Server</code> on the left hand side menu
- You will 3 file upload options fot uploading certifiates
- Upload local <code>fullchain.pem</code> for <code>Certificate</code> file upload
- Upload local <code>privkey.pem</code> for <code>Private Key</code> file upload
- Click on <code>Validate</code> and you will see new certificate results under <code>Validation Results</code>
- Now click on <code>Save</code>
- Click on <code>Update running server</code> if it pops up</p>

<p>And now you are done! Logout and login again or a new tab and you will see that new SSL works with no certificate warnings.</p>

<h3 id="step-6-%3A-creating-an-openvpn-user-%3A">Step 6 : Creating an OpenVPN user :</h3>

<p>You should never ever use the admin user <code>openvpn</code> to connect via vpn client! We will now create a new user.</p>

<ul>
<li>Visit <code>https://vpn.yourdomain.com:943/admin</code> and login with the admin credentials used earlier</li>
<li>Go to <code>User Management &gt; User Permissions</code> on the left hand side menu</li>
<li>Enter new username <code>vpnclientuser</code> and click on <code>More Settings</code> Dropdown to set a new passsword</li>
<li>Click on <code>Save Settings</code> and <code>Update existing server</code></li>
</ul>

<h3 id="final-step-%3A-login-with-vpn-%3A">Final step : Login with VPN :</h3>

<p>Go to your VPN client and enter host as <code>vpn.yourdomain.com</code> with username as <code>vpnclientuser</code> and the password you set for it. And Done!! You are connected.</p>

<p>If you do not have VPN client follow below steps :</p>

<ul>
<li>Visit <code>https://vpn.yourdomain.com:943</code> (Note that this url is not the admin login but a user login without /admin at the end)</li>
<li>Login with the user credentials with username as <code>vpnclientuser</code> and the password you set for it</li>
<li>Now you will see options to download VPN client or reset the user password if needed</li>
</ul>

<h3 id="cleanup-%3A">Cleanup :</h3>

<p>Now you are done with the OpenVPN server setup. I would recommend to remove the HTTP 22 inbound rule from <code>OpenVPN server SG</code> security group associated with the VPN server. This is because you would only need SSH access when you want to check logs or update some setup on OpenVPN. You can always go to AWS and open the port when needed.</p>

<p>Alternatively, change the source to your specific IP from which you SSH to the instance so that it is not open to the whole wide internet.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Manage laravel .env file using AWS parameter store]]></title>
            <link href="https://techsemicolon.github.io/blog/2019/07/10/aws-manage-env-file-using-ssm-laravel/"/>
            <updated>2019-07-10T00:00:00+00:00</updated>
            <id>https://techsemicolon.github.io/blog/2019/07/10/aws-manage-env-file-using-ssm-laravel/</id>
            <content type="html"><![CDATA[<p>When you have an application hosted on AWS EC2 instances which runs on an environment file, like laravel framework needs <code>.env</code> environment file, it is always a pain to manage environment variables.</p>

<p>Specially when you have multiple EC2 instances running for production on an auto-scaling setup. Please note that these are not host OS environment variable, but the application framework's environment variables in the respective env file.</p>

<p>You may alternatively call them application configuration files. You mostly do not add them in git or bitbucket due to the possibility of them containing sensitive information, e.g. database passwords, AWS access credentials etc..</p>

<h3 id="problem-statement-%3A">Problem statement :</h3>

<ul>
<li>You have environment .env file inside your EC2 AMI</li>
<li>When you spin up an instance, the .env file comes from the AMI specified in the launch configuration, considering you have auto-scaling set up</li>
<li>If you want to update any existing .env variable, you need to spin up new AMI and update production servers</li>
</ul>

<p>If your production environment has a setup like above, you may have experienced bit of pain in changing .env variables. Specially when there is a quick turnaround required due to some urgency or bug where you need to update an .env file variable asap.</p>

<h3 id="ec2-user_data-coming-to-rescue-%3A">EC2 user_data coming to rescue :</h3>

<p>When you spin up a new instance, you have an option in <code>Step 3: Configure Instance Details</code> screen inside <code>Advanced Details</code> called <code>user_data</code>. This looks something like below :</p>

<p>You can write shell scripts in text area or upload a bash file as per your choice. When you launch an instance in Amazon EC2, these shell scripts will be run after the instance starts. You can also pass cloud-init directives but we will stick to shell script for this use case to fetch the environment variables from systems manager parameter store and generate an environment file, in our case <code>.env</code> file under laravel root.</p>

<p><img src="/images/aws-ansible/user-data.png" alt="alt text1" /></p>

<h3 id="setting-up-variables-in-parameter-store-%3A">Setting up variables in parameter store :</h3>

<p>AWS has service called <code>Systems Manager</code> which contains a sub-service for resource sharing. This is called <code>Parameter Store</code>. There are couple of ways to store a parameter inside this service. We will be using <code>SecureString</code> option which makes sure the paramater value(which in our case is the enviromnent file contents) are encrypted inside AWS.</p>

<p>You may think that instead of storing entire .env file content into a single text-area, why should we not create multiple paremeters for each variable in the .env file? That's a perfectly valid point. However, storing it in one paramter store decreases overall maintenability and also makes the shell script to retrive those values very compact.</p>

<p>You can use below steps to store your <code>.env</code> file inside parameter store :</p>

<ol>
<li>Login to AWS console and switch to the region which contains your production setup</li>
<li>Go to <code>Systems Manager</code> and click on <code>Parameter Store</code></li>
<li>Click on <code>Create Parameter</code></li>
<li>Add <code>Name</code> and <code>Description</code></li>
<li>Select <code>Tier</code> as <code>Standard</code></li>
<li>Select <code>Type</code> as <code>SecureString</code></li>
<li>Select KMS key which managed encryption as per your choice</li>
<li>Enter entire <code>.env</code> contents into the text-area</li>
<li>Click on <code>Create Parameter</code> to save the parameter</li>
</ol>

<p><img src="/images/aws-ansible/create-parameter.png" alt="alt text1" /></p>

<h3 id="accessing-the-paremeter-store-values-%3A">Accessing the paremeter store values :</h3>

<p>Your EC2 instance which runs the application will be accessing these parameter store values. So you need to make sure your instance IAM role has following  permission in its policy.</p>

<pre><code class="json">{
    "Version": "2012-10-17",
            "Statement": [
        {
            "Sid": "VisualEditor1",
            "Effect": "Allow",
            "Action": [
                "ssm:GetParameters",
                "ssm:GetParameter",
            ],
            "Resource": [
                "arn:aws:ssm:*:*:parameter/*"
            ]
        }
    ]
}
</code></pre>

<h3 id="shell-script-to-generate-.env-%3A">Shell script to generate .env :</h3>

<p>We will be using following shell script to generate <code>.env</code> :</p>

<pre><code class="bash">#!/bin/bash

# Please update below varoables as per your production setup
PARAMATER="APP_ENV"
REGION="us-west-1"
WEB_DIR="/var/www/html"
WEB_USER="www-data"

# Get parameters and put it into .env file inside application root
aws ssm get-parameter --with-decryption --name $PARAMATER --region $REGION | jq '.Parameter.Value' &gt; $WEB_DIR/.env

# Clear laravel configuration cache
cd $WEB_DIR
chown $WEB_USER. .env
sudo -u $WEB_USER php artisan config:clear
</code></pre>

<h3 id="putting-pieces-together-%3A">Putting pieces together :</h3>

<p>Let us now consider a very generic overview of how these pieces will fit together :</p>

<ul>
<li>You will have your <code>.env</code> file stored in AWS systems manager parameter store with encryption enabled at rest</li>
<li>When a new instance will spin up, it will pull the env string and put into an <code>.env</code> file. This will happen using <code>user_data</code> setting</li>
<li>It will clear the application env cache or any dependent commands to take new environmental file into effect</li>
</ul>

<h3 id="fundamental-implementation-situations-%3A">Fundamental implementation situations :</h3>

<p>Let's say you have added a new variable in your env paramater group. You expect it to reflect ASAP in following situations :</p>

<ul>
<li><strong>All the new EC2 instances which will spin up after that point should always use the new env file variables</strong> :</li>
</ul>

<p>This can be easily implemented as we discussed earlier using <code>user_data</code>. When you spin up an instance manually you can add the above shell script to pull latest .env from parameter group in the <code>user_data</code> field.</p>

<p>If you have auto-scaling enabled, make sure your launch configuration or launch template has the <code>user_data</code> field set with the shell script we discussed in the previous section. This will then make sure, whenever a new EC2 instance will spin up, it will always fetch the environmental paramater first from AWS systems manager's parameter group store and then make a branch new <code>.env</code> file.</p>

<ul>
<li><strong>The existing instances which are already running should fetch the updated env file variables</strong> :</li>
</ul>

<p>Let's first take out the case where you have instance not in any auto-scaling group. You can then manually SSH into instance and fetch the new .env. (Or automate it using Solution B)</p>

<p>But in here main point of concern is when you have autoscaling setup and production is running on multiple instances. This is an area where we can have 2 solutions. First one is very easy to implement whereas second one can be a pain. Let's discuss both :</p>

<p><code>Solution A</code> :</p>

<p>From your existing auto-scaling instances, start terminating an instance one by one. Your auto-scaling setup will then spin up new instances. As we discussed earlier, considering your launch configuration already has the shell script to pull updated environment variables from parameter group at the instance start from <code>user_data</code> setting, the new instances will be ready with updated environmental veriables in their <code>.env</code> files.</p>

<p>To add more automation, you may also do the termination activity using a lambda function or ansible based on a trigger when systems manager's parameter group is updated.</p>

<p><code>Solution B</code> :</p>

<p>This is important for applications where there ephemeral storage is important for some ongoing tasks. If we terminate the instances, the production application will lose some of it's ongoing process data. In this case we need to find an automated way to run the shell script on all those running instances, to update their <code>.env</code> variables.</p>

<p>In this case, you can use AWS lambda for this purpose. The bottom line of this is <code>When systems manager's parameter group is updated, it will trigger a lambda function. That lambda function will SSH into all your running production instances and update the .env file</code>.</p>

<p>There is already a github repo I have added sometime back on running SSH commands on EC2 instances. You can <a href="https://github.com/techsemicolon/ec2-run-commands-log-output">click here</a> to know more about it.</p>

<h3 id="my-two-cents-%3A">My two cents :</h3>

<p>This may definitely appear as an overhead... But as your application becomes large, setting these things up will make your life so much easier.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Ansible everything you need to know about set_facts]]></title>
            <link href="https://techsemicolon.github.io/blog/2019/07/07/ansible-everything-you-need-to-know-about-set-facts/"/>
            <updated>2019-07-07T00:00:00+00:00</updated>
            <id>https://techsemicolon.github.io/blog/2019/07/07/ansible-everything-you-need-to-know-about-set-facts/</id>
            <content type="html"><![CDATA[<p>If you have seen lot of ansible playbook examples, <code>set_facts</code> module is very common in most of them. Let us dive little deeper to know what is it and how it may help you to write dynamic playbooks.</p>

<h3 id="the-jargon-%60set_facts%60--%3A">The jargon <code>set_facts</code>  :</h3>

<p>If you just read <code>set_facts</code> in an ansible playbook, it is really hard to interpret what it really means. You may think like it is setting some kind of facts but what facts? I had the same doubt and I was little overwhelmed by the terminology in here. But, to understand in generic terms :</p>

<p><code>set_facts</code> module sets variables once you know their values and optionally deciding if you need their values to be set or not.</p>

<p>You may set simple variables in ansible using <code>vars</code>, <code>vars_file</code> or <code>include_vars</code> modules, however you know their values beforehand. In case of <code>set_facts</code>, you set variables <code>on the fly</code> depending on certain task results. These variables will be available to be used in the subsequent plays during an ansible playbook execution.</p>

<h3 id="let%27s-see-a-real-life-use-case-%3A">Let's see a real life use case :</h3>

<p>Before diving into an actual playbook and overal syntax, let's first take a real life use case, which will help us connect the dots.</p>

<p>Use case : We need to spin up an instance on AWS and then add it into an existing AWS Target Group.</p>

<p>Known Variables : We will have some known variables like the instance AMI id and the instance type.</p>

<p>Unkwnon Variables : To add an instance to target group, we need the instance id. However, until that instance is spun up, we will not have the instance id. This will be set on the fly once instance is spun up.</p>

<p>In this case, we will use known variables to spin up an instance. Once that task is done, we will get an instance id from AWS. Thats a <code>fact</code> which we have come across from that task. We will set it to a variable using <code>set_facts</code> module and then it can be used later to add instance into an existing AWS Target Group.</p>

<h3 id="register-and-set_facts-go-hand-in-hand-%3A">Register and set_facts go hand in hand :</h3>

<p>Until you have receieved a factual information or to be specific, a task result, you do not have facts to set using <code>set_facts</code> module. This is why I always feel <code>register</code> module and <code>set_facts</code> module go hand in hand.</p>

<p>Please note that, there are lots of other ways to get factual information from a task and <code>register</code> is not the only way. But it is one of the most common ways you would get facts. Some other modules to get factual information can be <code>ansible_facts</code> to get package information (package_facts) from a host. The possibilities are much more.</p>

<h3 id="set_facts-is-host-specific-%3A">set_facts is host specific :</h3>

<p>A very important thing to note that when you set a fact using <code>set_facts</code> module, it is specific to the host within which task is currently running. As documentation says : <code>Variables are set on a host-by-host basis just like facts discovered by the setup module.</code> If your playbook has multiple hosts then you can not share a fact set using <code>set_facts</code> from one host to another.</p>

<h3 id="diving-into-an-example-%3A">Diving into an example :</h3>

<p>Let's take the use case we discussed earlier and make a simple playbook for it. We will have following structure :</p>

<pre><code>ReleaseAMIUpdates/
├── config.yml
├── env.yml
├── playbook.yml
└── setup.sh
</code></pre>

<p>Please note that you may have more detailed structure based on your preferences. This article is about exploring <code>set_facts</code>, so we will focus more on its implementation.</p>

<ul>
<li>config.yml :</li>
</ul>

<p>This file will have the configuration variables which rarely change.</p>

<pre><code class="yml">vpc_id: vpc-12345678
ec2_iam_role: ec2-iam-role-name
instance_type: t2.micro
instance_volume_in_gb: 30
instance_security_group: ec2-security-group-name
ami_id: ami-12345678
instance_key_name: ansible-instance.pem
</code></pre>

<ul>
<li>env.yml :</li>
</ul>

<p>This file will have the configurations which are sensitive and may change .</p>

<pre><code class="yml">region: us-west-1
aws_access_key: your_aws_access_key
aws_secret_key: your_aws_secret_key
target_group: Test Ansible Target Group
</code></pre>

<ul>
<li>setup.sh :</li>
</ul>

<p>This file will have any user-data boostrap commands you need to run as soon as new instance is spun up. We will use this to install nginx so that we can server web traffic with a simple web page.</p>

<pre><code class="bash">#!/bin/bash

# Update Package Lists
apt-get update

# Install add-apt-repository dependencies
apt-get install software-properties-common -y
apt-get install python-software-properties -y

# Update Package Lists
apt-get update -y

# Install nginx 
apt-get -y install nginx
</code></pre>

<p>Now you have above yml files set up, these files will act as environment variable files. We will refer the configurations specified above as variables in our playbook.</p>

<ul>
<li>playbook.yml :</li>
</ul>

<p>This file will contain all palybook tasks.
</p>

<pre><code class="yaml"># create a launch configuration using an AMI image and instance type as a basis
- name: Launch new AMI Release
  hosts: localhost
  connection: local
  vars_files:
    - ./env.yml
    - ./config.yml

  tasks:

  #  Get VPC public subnet details as it will be needed later while launching the sandbox instance
  - name: Get VPC Subnet Details
    ec2_vpc_subnet_facts:
      aws_access_key: "{{ aws_access_key }}"
      aws_secret_key: "{{ aws_secret_key }}"
      region: "{{ region }}"
      filters:
        vpc-id: "{{ vpc_id }}"
        "tag:Availability": "Public"
    # Save the result json in variable subnet_facts_public
    register: subnet_facts_public

  - name: Get VPC Subnet ids which are available and public
    set_fact:
      vpc_subnet_id_public: "{{ subnet_facts_public.subnets|selectattr('state', 'equalto', 'available')|map(attribute='id')|list|random }}"

  # Launch instance with required settings
  - name: Launch new instance
    ec2:
      key_name: "{{ instance_key_name }}"
      aws_access_key: "{{ aws_access_key }}"
      aws_secret_key: "{{ aws_secret_key }}"
      region: "{{ region }}"
      image: "{{ ami_id }}"
      instance_profile_name: "{{ ec2_iam_role }}"
      vpc_subnet_id: "{{ vpc_subnet_id_public }}"
      instance_type: "{{ instance_type }}"
      group: "{{ instance_security_group }}"
      assign_public_ip: False
      # All commands specified in below will run as soon as instance is launched
      user_data: "{{ lookup('file', 'setup.sh') }}"
      wait: True
      wait_timeout: 500
      volumes: 
        - device_name: /dev/sda1
          volume_size: "{{ instance_volume_in_gb }}"
          volume_type: gp2
          encrypted: True
          delete_on_termination: True
      instance_tags:
        Name: Ansible-Test-Instance
    register: ec2

  # Get instance id from registered facts in ec2
  - name: Get instance id from registered facts in ec2
    set_fact:
      new_instance_id: "{{ ec2.instance_ids[0] }}"

  # Add newly created instance into target group
  - name: Add newly created instance into target group
    elb_target_group:
      name: "{{ target_group }}"
      aws_access_key: "{{ aws_access_key }}"
      aws_secret_key: "{{ aws_secret_key }}"
      region: "{{ region }}"
      target_type: instance
      health_check_interval: 30
      health_check_path: /health
      health_check_protocol: http
      health_check_timeout: 15
      healthy_threshold_count: 2
      unhealthy_threshold_count: 2
      protocol: http
      port: 80
      vpc_id: "{{ _vpc_id }}"
      successful_response_codes: "200"
      targets:
        - Id: "{{ new_instance_id }}"
          Port: 80
      state: present

</code></pre>

<p>
Lets walk through each task in above <code>playbook.yml</code> first before we run it :</p>

<ol>
<li>We already know our vpc id. But to spin up an instance, we will need to get subnet id. We will use ansible module <code>ec2_vpc_subnet_facts</code> to get the public subnets. We will register that result into <code>subnet_facts_public</code> variable.</li>
<li>We will use <code>subnet_facts_public</code> variable to parse its content and get a public subnet which is available chosen randomly from set of available public subnets from the results. The type of parsing used is called <code>jinja</code> which comes within ansible. Once we have that fact, we will set it using <code>set_facts</code> into <code>vpc_subnet_id_public</code> variable on the fly.</li>
<li>We will launch new instance and then get its information. We will register that into <code>ec2</code> variable.</li>
<li>We will use <code>ec2</code> variable to parse its content and get the instance id of newly spun up instance. Once we have that fact, we will set it using <code>set_facts</code> into <code>new_instance_id</code> variable on the fly.</li>
<li>Finally we will update our target group and add this instance into its targets.</li>
</ol>

<h3 id="conditionally-set-facts-%3A">Conditionally set facts :</h3>

<p>You might need to set a fact using <code>set_facts</code> module when another variable or result registered contains some dependent value. In such case you can use <code>when</code> conditional.</p>

<p>Example :</p>

<p></p>

<pre><code class="yaml">- name: Get VPC Subnet ids which are available and public
    set_fact:
      vpc_subnet_id_public: "{{ subnet_facts_public.subnets|selectattr('state', 'equalto', 'available')|map(attribute='id')|list|random }}"
    when: region == "us-west-2" 
</code></pre>

<p></p>

<h3 id="caching-a-set-fact-%3A">Caching a set fact :</h3>

<p>You can cache a fact set from <code>set_facts</code> module so that when you execute your playbook next time, it's retrieved from cache. You can set <code>cacheable</code> to <code>yes</code> to store variables across your playbook executions using a fact cache. You may need to look into precedence strategies used by ansible to evaluate the cacheable facts mentioned in their <a href="https://docs.ansible.com/ansible/latest/modules/set_fact_module.html?highlight=set_facts">documentation</a>.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Ansible AWS rolling AMI update with zero downtime]]></title>
            <link href="https://techsemicolon.github.io/blog/2019/07/01/ansible-aws-rolling-ami-update-with-zero-downtime/"/>
            <updated>2019-07-01T00:00:00+00:00</updated>
            <id>https://techsemicolon.github.io/blog/2019/07/01/ansible-aws-rolling-ami-update-with-zero-downtime/</id>
            <content type="html"><![CDATA[<p>If you have website hosted on AWS with an Auto Scaling enabled, doing AMI rolling updates manually is a pain. But ansible makes it so much easy for you. Let's understand how you can save time and efforts for AMI rolling updates with zero downtime.</p>

<h3 id="what-is-a-rolling-ami-update-%3A">What is a rolling AMI update :</h3>

<p>When you have Auto Scaling enabled, AWS will scale up and down your setup by increasing or decreasing number of instances automatically based on server load and your auto scaling policies. AWS uses an instance template called <code>Launch Configuration</code> using which it understands what AMI to use when spinning up new instances automatically to scale up.</p>

<p>Now, lets assume that you have 4 instances currently in-service associated with your auto scaing with their AMI version as <code>V1</code>. Now you need to release a new AMI version <code>V2</code>. What you will ideally do is :</p>

<ul>
<li>Create a new launch configuration which points to new AMI version V2. To do it manually you will basicaly <code>copy</code> your existing launch configuration and update AMI id.</li>
<li>Edit your Auto Scaling group and associate it with newly created launch configuration.</li>
<li>By just doing above steps will not update the existing in-service instances. You will terminate the existing in-service instances one by one. Once an instance inside auto-scaling in-service listeners is terminated, auto scaling group will launch a new one to keep minimum number of instances in-service as per the auto scaling policy.</li>
<li>This new instance will now be from AMI version V2</li>
</ul>

<p>This is a rolling update, which most of the times is done manually. It takes approx 10-15 minutes to do it manually. Let's understand how you can do it under 2-3 minutes with ansible with 2-3 minutes rollback with just one configuration change.</p>

<h3 id="prerequisites-%3A">Prerequisites :</h3>

<p>You will need following before you start working on ansible playbook and it's tasks :</p>

<ul>
<li>You will need <code>ansible 2.8.x</code> and <code>boto3</code> installed on the system. Preferred way to install these is using <code>pip</code> installer.</li>
<li>You will need an AWS CLI user with access key and secret access key. I always prefer doing this in a non-production region first so that if you mess up anything, there is minimum worry. Let's say your production AWS region is <code>us-west-1</code> then you woul setup a clone in <code>us-west-2</code> and then test ansible playbook in there. You can use below IAM policy for the CLI user</li>
</ul>

<pre><code class="json">{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ec2:*",
                "rds:*",
                "lambda:*",
                "autoscaling:*",
                "iam:PassRole",
                "elasticloadbalancing:*"
            ],
            "Resource": "*",
            "Condition": {
                "StringEquals": {
                    "aws:RequestedRegion": "us-west-2"
                }
            }
        }
    ]
}
</code></pre>

<h3 id="setup-%3A">Setup :</h3>

<p>We will have following structure :</p>

<pre><code>ReleaseAMIUpdates/
├── config.yml
├── env.yml
├── playbook.yml
└── startup.sh
</code></pre>

<ul>
<li>config.yml :</li>
</ul>

<p>This file will have the configuration variables which rarely change.</p>

<pre><code class="yml">project_lunch_config_name: Production Launch configuration
project_autoscaling_group_name: Prod Auto Scaling Group
project_vpc_id: vpc-12345678
project_ec2_iam_role: ec2-iam-role-name
project_instance_type: t2.micro
project_instance_volume_in_gb: 30
project_instance_security_group: ec2-security-group-name
</code></pre>

<ul>
<li>env.yml :</li>
</ul>

<p>This file will have the configurations which are sensitive and may change in each rolling update.</p>

<pre><code class="yml">project_region: us-west-1
project_aws_access_key: your_aws_access_key
project_aws_secret_key: your_aws_secret_key
project_golden_ami_id: ami-version-id
project_ami_version: V2
project_target_group_arn: arn:aws:elasticloadbalancing:us-west-2:123456789:targetgroup/Your-TargetGroup/233vc4441187369
</code></pre>

<ul>
<li>startup.sh :</li>
</ul>

<p>This file will have any user-data boostrap commands you need to run as soon as new instance is spun up.</p>

<pre><code class="bash">#!/bin/bash

# Add your commands here
# These will run as root
# Which means ~ refers to /root
</code></pre>

<p>Now you have above yml files set up, these files will act as environment variable files. We will refer the configurations specified above as variables in our playbook.</p>

<ul>
<li>playbook.yml :</li>
</ul>

<p>This file will contain all palybook tasks.
</p>

<pre><code class="yaml"># create a launch configuration using an AMI image and instance type as a basis
- name: Launch new AMI Release
  hosts: localhost
  connection: local
  vars_files:
    - ./env.yml
    - ./config.yml

  tasks:

  #  Get VPC subnet details as it will be needed later while setting up autoscaling group
  - name: Get VPC Subnet Details
    ec2_vpc_subnet_facts:
      aws_access_key: "{{ project_aws_access_key }}"
      aws_secret_key: "{{ project_aws_secret_key }}"
      region: "{{ project_region }}"
      filters:
        vpc-id: "{{ project_vpc_id }}"
        "tag:Availability": "Private"
    # Save the result json in variable subnet_facts
    register: subnet_facts

  # From the previously registered variable subnet_facts
  # Get filter subnet which are in avaible state
  # Use jinja to parse json and get list of ids
  # This list will be used directly while setting up autoscaling group
  - name: Get VPC Subnet ids which are available
    set_fact:
      vpc_subnet_ids: "{{ subnet_facts.subnets|selectattr('state', 'equalto', 'available')|map(attribute='id')|list }}"

  # Create new launch configuration as existing one can not be edited
  # This launch configuration will contain the new AMI
  - name: Configure new launch configuration
    ec2_lc:
      aws_access_key: "{{ project_aws_access_key }}"
      aws_secret_key: "{{ project_aws_secret_key }}"
      region: "{{ project_region }}"
      name: "{{ project_lunch_config_name }}"
      # This image Id will be the new golden AMI after release is complete
      image_id: "{{ project_golden_ami_id }}"
      instance_profile_name: "{{ project_ec2_iam_role }}"
      vpc_id: "{{ project_vpc_id }}"
      security_groups: ["{{ project_instance_security_group }}"]
      instance_type: "{{ project_instance_type }}"
      # All commands specified in below ./startup.sh will run as soon as instance is launched
      user_data_path: ./startup.sh
      volumes:
      - device_name: /dev/sda1
        volume_size: "{{ project_instance_volume_in_gb }}"
        volume_type: gp2
        iops: 3000
        delete_on_termination: true
        encrypted: true

  # Update autoscaling group and associate new launch configuration
  # As there is no AMI just to update an existing autoscaling group
  # We specify all options and ansible will match the name to update
  - name: Update Auto Scalling Group with new launch configuration
    ec2_asg:
      aws_access_key: "{{ project_aws_access_key }}"
      aws_secret_key: "{{ project_aws_secret_key }}"
      name: "{{ project_autoscaling_group_name }}"
      region: "{{ project_region }}"
      launch_config_name: "{{ project_lunch_config_name }}"
      default_cooldown: 180
      health_check_period: 300
      health_check_type: ELB
      target_group_arns: ["{{ project_target_group_arn }}"]
      desired_capacity: 4
      min_size: 4
      max_size: 6
      vpc_zone_identifier: "{{ vpc_subnet_ids }}"
      # Below settings will replace all existing instances in this autoscaling group
      # With instances of new AMI release
      # The replacing will happen in batches with 2 instances replaced at at time
      replace_all_instances: true
      replace_batch_size: 2
      # We will wait untill all newly replaced instances are healthy and in service
      # Max wait time will be 10 minutes after which ansible will time out
      # In case of timeout the activity will keep happening on AWS
      # Just that the terminal will not wait for the output and exit with code 0
      wait_for_instances: true
      wait_timeout: 600
      # Below tabs will be present on all production instances launched with new AMI
      tags:
      - Environment: Production
        Name : "Production instances | {{ project_ami_version }}"
        Project: Your Project Name
        Vesion : "{{ project_ami_version }}"
</code></pre>

<p>
Lets walk through each task in above <code>playbook.yml</code> first before we run it :</p>

<ol>
<li><p>Get VPC Subnet Details : The instances will be launched in a VPC. We will need the subnet ids from the VPC we will need instances to be present in. In here I have used a tag <code>Availability:Private</code> to only get private instances as in my setup, instances are not publically accessible from a public subnet.</p></li>
<li><p>Get VPC Subnet ids which are available : The 1st task will give us entire json details of VPC subnets. This task will filter and get only ids using jinja parsing of the json result.</p></li>
<li><p>Configure new launch configuration : We will create a new launch configuration. I have been very descriptive in the options used in this task to make sure it's easy to refer next time.</p></li>
<li><p>Update Auto Scalling Group with new launch configuration : This will associate the new launch configuration to an existing auto scaling group. Make sure your auto scaling group name matches to the one present already so that it's updated properly. The <code>replace_all_instances: true</code> makes sure we are rolling the new AMIs instantly. This task will wait for the instances to spin up and be <code>in-service</code> state. This is sepcified by <code>wait_for_instances</code> and <code>wait_timeout</code> options in this task.</p></li>
</ol>

<h3 id="running-the-playbook-%3A">Running the playbook :</h3>

<p>First step is to make sure you have correct variables set in the <code>env.yml</code> and <code>config.yml</code>. When you do it for the second time, you will just need to change <code>project_golden_ami_id</code> and <code>project_ami_version</code> variables.</p>

<p>Before running it directly, it's always safe to run it using <code>--check</code> mode as a dryrun, with -vv to have more verbose output :</p>

<pre><code class="bash">ansible-playbook playbook.yml -vv --check
</code></pre>

<p>Deploying the new AMI :</p>

<pre><code class="bash">ansible-playbook playbook.yml -vv
</code></pre>

<h3 id="rolling-back-the-update-%3A">Rolling back the update :</h3>

<p>If your AMI which was newly released had issues, you can easily roll it back by specifying old stable values in <code>project_golden_ami_id</code> and <code>project_ami_version</code> variables. Then you just need to deploy the playbook.</p>

<h3 id="why-to-invest-time-in-ansible-%3A">Why to invest time in ansible :</h3>

<p>As your AWS setup grows, the manual activities which were simple at first become start becoming an overhead. Plus, there is always a risk of errors when manual operations are concerned. Using an automation tool like ansible lets you do the same actions with 70-80% less time than you would need to do it manually. Also ansible playbooks become a reference documentation if you need to explain anyone from your team how AMI updates are performed.</p>

<h3 id="tracking-ansible-playbooks-in-git-repo-%3A">Tracking ansible playbooks in git repo :</h3>

<p>If you want to track these ansible playbooks in git, make sure you do not track the main <code>env.yml</code> file which has AWS CLI crednetials. That is why we have 2 separate files <code>env.yml</code> and <code>config.yml</code>.</p>

<h3 id="improvements-%3A">Improvements :</h3>

<p>If you would like, you can update the AWS CLI user IAM policy to add more granuler permissions which is always preferable.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[AWS Load Balancer stickiness and load distribution]]></title>
            <link href="https://techsemicolon.github.io/blog/2019/04/19/aws-load-balancer-stickiness-load-distribution/"/>
            <updated>2019-04-19T00:00:00+00:00</updated>
            <id>https://techsemicolon.github.io/blog/2019/04/19/aws-load-balancer-stickiness-load-distribution/</id>
            <content type="html"><![CDATA[<p>AWS load balancing is an interesting cloud service which automatically distributes incoming application traffic across multiple available target servers, such as Amazon EC2 instances, containers, IP addresses, and Lambda functions. It helps the infrastructure to have high availability, automatic scaling and as a result makes application more fault tolerant.</p>

<ul>
<li>Quick question :</li>
</ul>

<p>As per the concept of AWS load balancer with autoscaling, if the traffic is increased which current servers can not handle, new server is launched automatically and added under the load balancer so that the traffic is distributed across available target servers.</p>

<p>Let's say for an example :</p>

<p>We have an Application load balancer(ALB) which has minimum 2 servers, maximum it can autoscale to 10 servers. Each server can serve user traffic for 50 users.</p>

<p>The server has autoscaling policy based on <code>CPUUtilization</code>, when server goes above 75% for CPUUtilization metrix, autoscaling shoul spin up new instance.</p>

<p>At 8AM there are 50 users, the traffic is distributed across 2 servers and everything is normal.
AT 10AM there are 95 user and the CPUUtilization is greater than 75% threashold, a new server spins up.</p>

<p>Now, at 10.15AM can you be sure that the traffic load is distributed evenly by the autoscaling?</p>

<ul>
<li>Let's find out :</li>
</ul>

<ol>
<li>Server spin up time :</li>
</ol>

<p>Server spin up time, also called as instance warmup time, is the duration in which server spin up is initiated and server is ready to server requests. This depends upon the configuration scripts and start up commands which are run when server is spinning up.</p>

<p>The instances use a configuration script to install and configure software before the instance is put into service. As a result, it takes around two or three minutes from the time the instance launches until it comes in service. This is not entirely in our hands and AWS internal infrastructure also contributes to this time. The actual time depends on several factors, such as the size of the instance and whether there are startup scripts to complete.</p>

<p>However, this is important to know how much time your server takes on an average to be ready. Because if your server takes on an average 15 minutes to spin up, all the increased traffic will still served by old overwhelmed servers for that 15 minute period.</p>

<p>AWS uses <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html">cooldown period</a> setting for simple autoscaling policy to handle the startup time.</p>

<ol start="2">
<li>Sticky session or stickyness of the load balancer :</li>
</ol>

<p><a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-target-groups.html#sticky-sessions">Sticky session</a> or stickyness of load balancer the setting to route the traffic incoming requests for a particular session to the same target server that serviced the initial request for that session. In short, under load balancer having 3 servers S1, S2 and S3, if User A's first request was served by S2 server, his subsqeuent requests will be also served by S2 server until the request stickyness is expired or disabled or deliberatly updated(by sending differnet AWSALB cookie in request)</p>

<p>More interestingly, the load balancer will always distribute traffic in a round robin algorithm. This is done with each request without stickiness and done on each session with stickiness.</p>

<p>As soon as a new instance is spun up and joins the group, it will not immediately get all the traffic. but it will join in the pool of round robin distribution of incoming traffic.</p>

<p>With stickiness setting enabled, existing sessions <code>will still have all requests routed to existing instances</code>. Only <code>new</code> sessions may hit the new instance. Being round robin, new sessions may also get routed to the existing instances.</p>

<p>Without stickiness, request from existing users will immediately get routed to the new instance. Hence it's safe to say that how quickly traffic load will be equilized and distributed across all available instances will depend on stickiness.</p>

<p>Sticky session comes up with a setting of expiration. You can specify a time from 1 second to 7 days. This setting is really important and you should definitely pay attension to the value you are setting. If this value is very large, spinning up new instances when autoscaling kicks in will not be useful as existing traffic is still stick with old servers.</p>

<p>Also a key point to note that for sticky session expiration Period, type the cookie expiration period, in seconds. If you do not specify an expiration period, the sticky session lasts for the duration of the browser session.</p>

<ul>
<li>Know if you need sticky sessions :</li>
</ul>

<p>Even if the sticky session setting is a good choice, it's for the applications which maintain the session state on service target instance. For example, a php web server maintaining sessions in local filesystem of EC2 instance. In that case if user request is served by other EC2 instance, then user will be logged out die to that session not being present there.</p>

<p>However, if your session state is managed by a separate service like RDS, Redis, Elasticache etc which is independent of which target server is serving your request, you probably do not even need sticky sessions.</p>

<ul>
<li>The bottom line :</li>
</ul>

<p>Test and find the best settings as per your application when setting up auto-scaling policies. Because, if your server is not ready quickly when the application needs it for serving increased traffic, it's going to affect your application performance specially during peak hours.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Laravel use secure SSL connection while using AWS RDS]]></title>
            <link href="https://techsemicolon.github.io/blog/2019/04/10/laravel-rds-ssl-encryption-in-transit/"/>
            <updated>2019-04-10T00:00:00+00:00</updated>
            <id>https://techsemicolon.github.io/blog/2019/04/10/laravel-rds-ssl-encryption-in-transit/</id>
            <content type="html"><![CDATA[<p>Amazon Relational Database Service Amazon RDS is a cloud based web service that makes things easier to set up, operate, and scale a relational databases on the cloud. It has become one of the popular choices when setting up laravel database infrastructure.</p>

<ul>
<li>Quick question :</li>
</ul>

<p>If you are using AWS RDS in your laravel application, is your connection encrypted in transit? Or so ask other way around, is your laravel application connecting to AWS RDS using a secure SSL connection?</p>

<p>If you think that RDS comes up with secure encryption in transit, you are right, it implements SSL. However, is it turned on somehow by default or is it there when we use it directly? Not really.. I had a perception that my laravel app is secured in transit by SSL encryption until I found out its not.</p>

<ul>
<li>Let's find out :</li>
</ul>

<p>Connect to the environment/server/container where laravel is hosted and run tinker :</p>

<pre><code class="bash">php artisan tinker
</code></pre>

<p>Once, the tinker prompt is open, run following :</p>

<pre><code class="bash">&gt;&gt;&gt; DB::select("SHOW STATUS LIKE 'Ssl_cipher'")
</code></pre>

<p>If it gives output like following :</p>

<pre><code class="bash">=&gt; [
    {
        +"Variable_name": "Ssl_cipher",
        +"Value": "DHE-RSA-AES128-SHA",
    },
]
</code></pre>

<p>Then laravel application is connecting to AWS RDS via a secure SSL connection.</p>

<p>However, if the output is like this  :</p>

<pre><code class="bash">=&gt; [
    {
        +"Variable_name": "Ssl_cipher",
        +"Value": "",
    },
]
</code></pre>

<p>Then the connection is not sure. There are number of variables which you can help us get more information about the SSL connection paramaters. We checked <code>Ssl_cipher</code> above, you can also check <code>Ssl_version</code> which might give you blank or something like <code>TLSv1</code> if SSL is working.</p>

<p>To get all information about SSL connection run following in tinker prompt :</p>

<pre><code class="bash">&gt;&gt;&gt; DB::select("SHOW STATUS LIKE '%Ssl%'")
</code></pre>

<ul>
<li>Next steps to secure the connection :</li>
</ul>

<p>If you found out that the laravel application connection is not using SSL while connecting to AWS RDS, you can follow below steps to enable the same.</p>

<p>Firstly, let us understand how it works. When you connect to AWS RDS normally via mysql cli, you do :</p>

<pre><code class="bash">mysql -h myinstance.c9akciq32.rds-us-east-1.amazonaws.com -u username -p
</code></pre>

<p>You can pass SSL certificate using <code>--ssl-ca</code> option in above command like below :</p>

<pre><code class="bash">mysql -h myinstance.c9akciq32.rds-us-east-1.amazonaws.com --ssl-ca=/path/to/certificate-authority-file.pem -u username -p
</code></pre>

<p>Optionally, you can pass <code>-ssl-mode</code> and <code>--ssl-verify-server-cert</code>. For more details about this please refer mysql's official <a href="https://dev.mysql.com/doc/refman/5.7/en/encrypted-connection-options.html">documentation</a>.</p>

<p>Now let's get back to the original problem which we are here to solve. How we are going to do this in Laravel?</p>

<p>Step 1 : Downloading the <code>certificate authority file</code>. AWS RDS has a commonly published pem file called <code>rds-combined-ca-bundle.pem</code> which you can download directly from <a href="https://s3.amazonaws.com/rds-downloads/rds-combined-ca-bundle.pem">here</a>. It is an officially published pem file which will work in all default RDS SSL connections.</p>

<p>Step 2 : Save the downloaded file from step 1 inside a new directory called <code>RDSCerts</code> inside laravel root. Quick note that in this step itself, I would add this inside gitignore because there is no need to add pem and cert files inside the version control.</p>

<p>Step 3 : Laravel's database configurations are inside <code>config/database.php</code> file. It already has a <code>mysql</code> section. Let's not change that, lets copy that entirely into a new configuration section called <code>mysql_ssl</code> where we will also add the certification authority file in options like below :</p>

<pre><code class="php">'mysql_ssl' =&gt; [
    'driver' =&gt; 'mysql',
    'host' =&gt; env('DB_HOST', '127.0.0.1'),
    'port' =&gt; env('DB_PORT', '3306'),
    'database' =&gt; env('DB_DATABASE', 'forge'),
    'username' =&gt; env('DB_USERNAME', 'forge'),
    'password' =&gt; env('DB_PASSWORD', ''),
    'unix_socket' =&gt; env('DB_SOCKET', ''),
    'charset' =&gt; 'utf8mb4',
    'collation' =&gt; 'utf8mb4_unicode_ci',
    'prefix' =&gt; '',
    'prefix_indexes' =&gt; true,
    'strict' =&gt; false,
    'engine' =&gt; null,
    'options' =&gt; [    
        PDO::MYSQL_ATTR_SSL_CA =&gt; base_path('RDSCerts/rds-combined-ca-bundle.pem')
    ],
],
</code></pre>

<p>Important note, You might be thinking that when we need to pass <code>--ssl-verify-server-cert</code> option somehow from laravel's configuration as well. Don't worry it's enabled by default. If you want to disable it then you can pass <code>PDO::MYSQL_ATTR_SSL_VERIFY_SERVER_CERT = false</code> which I would not suggest.</p>

<p>There are more options about SSL which you can check in the official PDO <a href="https://www.php.net/manual/en/ref.pdo-mysql.php">documentation</a>.</p>

<p>Once you follow above 3 steps, you should be good to go. Cross check by running <code>DB::select("SHOW STATUS LIKE '%Ssl%'")</code> in tinker as we did earlier in this article. You should see ciphers and ssl version mentioned in the connection.</p>
]]></content>
        </entry>
    </feed>