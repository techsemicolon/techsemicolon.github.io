<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title><![CDATA[Tech.Semicolon]]></title>
    <link href="https://techsemicolon.github.io/blog/tags/aws.xml" rel="self"/>
    <link href="https://techsemicolon.github.io/"/>
    <updated>2019-09-09T06:53:17+00:00</updated>
    <id>https://techsemicolon.github.io/</id>
        <generator uri="http://sculpin.io/">Sculpin</generator>
            <entry>
            <title type="html"><![CDATA[Ansible everything you need to know about set_facts]]></title>
            <link href="https://techsemicolon.github.io/blog/2019/07/07/ansible-everything-you-need-to-know-about-set-facts/"/>
            <updated>2019-07-07T00:00:00+00:00</updated>
            <id>https://techsemicolon.github.io/blog/2019/07/07/ansible-everything-you-need-to-know-about-set-facts/</id>
            <content type="html"><![CDATA[]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Ansible AWS rolling AMI update with zero downtime]]></title>
            <link href="https://techsemicolon.github.io/blog/2019/07/01/ansible-aws-rolling-ami-update-with-zero-downtime/"/>
            <updated>2019-07-01T00:00:00+00:00</updated>
            <id>https://techsemicolon.github.io/blog/2019/07/01/ansible-aws-rolling-ami-update-with-zero-downtime/</id>
            <content type="html"><![CDATA[<p>If you have website hosted on AWS with an Auto Scaling enabled, doing AMI rolling updates manually is a pain. But ansible makes it so much easy for you. Let's understand how you can save time and efforts for AMI rolling updates with zero downtime.</p>

<h3 id="what-is-a-rolling-ami-update-%3A">What is a rolling AMI update :</h3>

<p>When you have Auto Scaling enabled, AWS will scale up and down your setup by increasing or decreasing number of instances automatically based on server load and your auto scaling policies. AWS uses an instance template called <code>Launch Configuration</code> using which it understands what AMI to use when spinning up new instances automatically to scale up.</p>

<p>Now, lets assume that you have 4 instances currently in-service associated with your auto scaing with their AMI version as <code>V1</code>. Now you need to release a new AMI version <code>V2</code>. What you will ideally do is :</p>

<ul>
<li>Create a new launch configuration which points to new AMI version V2. To do it manually you will basicaly <code>copy</code> your existing launch configuration and update AMI id.</li>
<li>Edit your Auto Scaling group and associate it with newly created launch configuration.</li>
<li>By just doing above steps will not update the existing in-service instances. You will terminate the existing in-service instances one by one. Once an instance inside auto-scaling in-service listeners is terminated, auto scaling group will launch a new one to keep minimum number of instances in-service as per the auto scaling policy.</li>
<li>This new instance will now be from AMI version V2</li>
</ul>

<p>This is a rolling update, which most of the times is done manually. It takes approx 10-15 minutes to do it manually. Let's understand how you can do it under 2-3 minutes with ansible with 2-3 minutes rollback with just one configuration change.</p>

<h3 id="prerequisites-%3A">Prerequisites :</h3>

<p>You will need following before you start working on ansible playbook and it's tasks :</p>

<ul>
<li>You will need <code>ansible 2.8.x</code> and <code>boto3</code> installed on the system. Preferred way to install these is using <code>pip</code> installer.</li>
<li>You will need an AWS CLI user with access key and secret access key. I always prefer doing this in a non-production region first so that if you mess up anything, there is minimum worry. Let's say your production AWS region is <code>us-west-1</code> then you woul setup a clone in <code>us-west-2</code> and then test ansible playbook in there. You can use below IAM policy for the CLI user</li>
</ul>

<pre><code class="json">{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ec2:*",
                "rds:*",
                "lambda:*",
                "autoscaling:*",
                "iam:PassRole",
                "elasticloadbalancing:*"
            ],
            "Resource": "*",
            "Condition": {
                "StringEquals": {
                    "aws:RequestedRegion": "us-west-2"
                }
            }
        }
    ]
}
</code></pre>

<h3 id="setup-%3A">Setup :</h3>

<p>We will have following structure :</p>

<pre><code>ReleaseAMIUpdates/
├── config.yml
├── env.yml
├── playbook.yml
└── startup.sh
</code></pre>

<ul>
<li>config.yml :</li>
</ul>

<p>This file will have the configuration variables which rarely change.</p>

<pre><code class="yml">project_lunch_config_name: Production Launch configuration
project_autoscaling_group_name: Prod Auto Scaling Group
project_vpc_id: vpc-12345678
project_ec2_iam_role: ec2-iam-role-name
project_instance_type: t2.micro
project_instance_volume_in_gb: 30
project_instance_security_group: ec2-security-group-name
</code></pre>

<ul>
<li>env.yml :</li>
</ul>

<p>This file will have the configurations which are sensitive and may change in each rolling update.</p>

<pre><code class="yml">project_region: us-west-1
project_aws_access_key: your_aws_access_key
project_aws_secret_key: your_aws_secret_key
project_golden_ami_id: ami-version-id
project_ami_version: V2
project_target_group_arn: arn:aws:elasticloadbalancing:us-west-2:123456789:targetgroup/Your-TargetGroup/233vc4441187369
</code></pre>

<ul>
<li>startup.sh :</li>
</ul>

<p>This file will have any user-data boostrap commands you need to run as soon as new instance is spun up.</p>

<pre><code class="bash">#!/bin/bash

# Add your commands here
# These will run as root
# Which means ~ refers to /root
</code></pre>

<p>Now you have above yml files set up, these files will act as environment variable files. We will refer the configurations specified above as variables in our playbook.</p>

<ul>
<li>playbook.yml :</li>
</ul>

<p>This file will contain all palybook tasks.
</p>

<pre><code class="yaml"># create a launch configuration using an AMI image and instance type as a basis
- name: Launch new AMI Release
  hosts: localhost
  connection: local
  vars_files:
    - ./env.yml
    - ./config.yml

  tasks:

  #  Get VPC subnet details as it will be needed later while setting up autoscaling group
  - name: Get VPC Subnet Details
    ec2_vpc_subnet_facts:
      aws_access_key: "{{ project_aws_access_key }}"
      aws_secret_key: "{{ project_aws_secret_key }}"
      region: "{{ project_region }}"
      filters:
        vpc-id: "{{ project_vpc_id }}"
        "tag:Availability": "Private"
    # Save the result json in variable subnet_facts
    register: subnet_facts

  # From the previously registered variable subnet_facts
  # Get filter subnet which are in avaible state
  # Use jinja to parse json and get list of ids
  # This list will be used directly while setting up autoscaling group
  - name: Get VPC Subnet ids which are available
    set_fact:
      vpc_subnet_ids: "{{ subnet_facts.subnets|selectattr('state', 'equalto', 'available')|map(attribute='id')|list }}"

  # Create new launch configuration as existing one can not be edited
  # This launch configuration will contain the new AMI
  - name: Configure new launch configuration
    ec2_lc:
      aws_access_key: "{{ project_aws_access_key }}"
      aws_secret_key: "{{ project_aws_secret_key }}"
      region: "{{ project_region }}"
      name: "{{ project_lunch_config_name }}"
      # This image Id will be the new golden AMI after release is complete
      image_id: "{{ project_golden_ami_id }}"
      instance_profile_name: "{{ project_ec2_iam_role }}"
      vpc_id: "{{ project_vpc_id }}"
      security_groups: ["{{ project_instance_security_group }}"]
      instance_type: "{{ project_instance_type }}"
      # All commands specified in below ./startup.sh will run as soon as instance is launched
      user_data_path: ./startup.sh
      volumes:
      - device_name: /dev/sda1
        volume_size: "{{ project_instance_volume_in_gb }}"
        volume_type: gp2
        iops: 3000
        delete_on_termination: true
        encrypted: true

  # Update autoscaling group and associate new launch configuration
  # As there is no AMI just to update an existing autoscaling group
  # We specify all options and ansible will match the name to update
  - name: Update Auto Scalling Group with new launch configuration
    ec2_asg:
      aws_access_key: "{{ project_aws_access_key }}"
      aws_secret_key: "{{ project_aws_secret_key }}"
      name: "{{ project_autoscaling_group_name }}"
      region: "{{ project_region }}"
      launch_config_name: "{{ project_lunch_config_name }}"
      default_cooldown: 180
      health_check_period: 300
      health_check_type: ELB
      target_group_arns: ["{{ project_target_group_arn }}"]
      desired_capacity: 4
      min_size: 4
      max_size: 6
      vpc_zone_identifier: "{{ vpc_subnet_ids }}"
      # Below settings will replace all existing instances in this autoscaling group
      # With instances of new AMI release
      # The replacing will happen in batches with 2 instances replaced at at time
      replace_all_instances: true
      replace_batch_size: 2
      # We will wait untill all newly replaced instances are healthy and in service
      # Max wait time will be 10 minutes after which ansible will time out
      # In case of timeout the activity will keep happening on AWS
      # Just that the terminal will not wait for the output and exit with code 0
      wait_for_instances: true
      wait_timeout: 600
      # Below tabs will be present on all production instances launched with new AMI
      tags:
      - Environment: Production
        Name : "Production instances | {{ project_ami_version }}"
        Project: Your Project Name
        Vesion : "{{ project_ami_version }}"
</code></pre>

<p>
Lets walk through each task in above <code>playbook.yml</code> first before we run it :</p>

<ol>
<li><p>Get VPC Subnet Details : The instances will be launched in a VPC. We will need the subnet ids from the VPC we will need instances to be present in. In here I have used a tag <code>Availability:Private</code> to only get private instances as in my setup, instances are not publically accessible from a public subnet.</p></li>
<li><p>Get VPC Subnet ids which are available : The 1st task will give us entire json details of VPC subnets. This task will filter and get only ids using jinja parsing of the json result.</p></li>
<li><p>Configure new launch configuration : We will create a new launch configuration. I have been very descriptive in the options used in this task to make sure it's easy to refer next time.</p></li>
<li><p>Update Auto Scalling Group with new launch configuration : This will associate the new launch configuration to an existing auto scaling group. Make sure your auto scaling group name matches to the one present already so that it's updated properly. The <code>replace_all_instances: true</code> makes sure we are rolling the new AMIs instantly. This task will wait for the instances to spin up and be <code>in-service</code> state. This is sepcified by <code>wait_for_instances</code> and <code>wait_timeout</code> options in this task.</p></li>
</ol>

<h3 id="running-the-playbook-%3A">Running the playbook :</h3>

<p>First step is to make sure you have correct variables set in the <code>env.yml</code> and <code>config.yml</code>. When you do it for the second time, you will just need to change <code>project_golden_ami_id</code> and <code>project_ami_version</code> variables.</p>

<p>Before running it directly, it's always safe to run it using <code>--check</code> mode as a dryrun, with -vv to have more verbose output :</p>

<pre><code class="bash">ansible-playbook playbook.yml -vv --check
</code></pre>

<p>Deploying the new AMI :</p>

<pre><code class="bash">ansible-playbook playbook.yml -vv
</code></pre>

<h3 id="rolling-back-the-update-%3A">Rolling back the update :</h3>

<p>If your AMI which was newly released had issues, you can easily roll it back by specifying old stable values in <code>project_golden_ami_id</code> and <code>project_ami_version</code> variables. Then you just need to deploy the playbook.</p>

<h3 id="why-to-invest-time-in-ansible-%3A">Why to invest time in ansible :</h3>

<p>As your AWS setup grows, the manual activities which were simple at first become start becoming an overhead. Plus, there is always a risk of errors when manual operations are concerned. Using an automation tool like ansible lets you do the same actions with 70-80% less time than you would need to do it manually. Also ansible playbooks become a reference documentation if you need to explain anyone from your team how AMI updates are performed.</p>

<h3 id="tracking-ansible-playbooks-in-git-repo-%3A">Tracking ansible playbooks in git repo :</h3>

<p>If you want to track these ansible playbooks in git, make sure you do not track the main <code>env.yml</code> file which has AWS CLI crednetials. That is why we have 2 separate files <code>env.yml</code> and <code>config.yml</code>.</p>

<h3 id="improvements-%3A">Improvements :</h3>

<p>If you would like, you can update the AWS CLI user IAM policy to add more granuler permissions which is always preferable.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[AWS update AMI using systems manager automation]]></title>
            <link href="https://techsemicolon.github.io/blog/2019/06/10/aws-update-ami-systems-manager-automation/"/>
            <updated>2019-06-10T00:00:00+00:00</updated>
            <id>https://techsemicolon.github.io/blog/2019/06/10/aws-update-ami-systems-manager-automation/</id>
            <content type="html"><![CDATA[<h4 id="overview-%3A">Overview :</h4>

<p>Having am AMI(Amazon Machine Image) of the most stable production server is a very common practice. On top of that adding maintenance scripts, installing new softwares or patching hotfixes are some of the common actions we need to perform on AMI.</p>

<p>The general flow in simple terms is :</p>

<pre><code>- Take an existing AMI(Let's call it AMI-V1)
- Launch an instance originating from the AMI-V1
- SSH into the new instance
- Run maintenance or installation commands
- Create a new AMI(Let's call it AMI-V2)
- Terminate the tempararily launched instance
- Optionally if you have autoscaling group launch configurations, then update it's association with new AMI-V2
</code></pre>

<p>If you do all above steps manually, there is nothing wrong in it. However, AWS has a service called <code>Systems Manager</code> which has a sub-service <code>automation</code>. It can help you to automate and also optionally schedule these AMI updates automatically. Trust me! If you know how to do it once, you will never go back to manual updates.</p>

<h4 id="how-it-works-%3A">How it works :</h4>

<p>SSM's automation service has different types. Those are called <code>Executions</code>. When you add details on what and how to setup that execution, the entire thing is called <code>Execution Document</code>. Dont worry, it's not that important to remember these names as long as you know how to use it.</p>

<p>There are many different types of executions available in automation service. One which we are looking for is called <a href="https://eu-west-2.console.aws.amazon.com/systems-manager/documents/AWS-UpdateLinuxAmi/description?region=eu-west-2"><code>AWS-UpdateLinuxAmi</code></a>. This execution helps us to automate updates to AMI with Linux distribution packages and Amazon software.</p>

<p>When you create the execution to automate the AMI updates, you can specify which AMI to update, specify the script of commands to run and specify the new AMI name. There are more steps to it which we will cover in <code>Implementation</code> section down below.</p>

<h4 id="prerequisites-and-difficult-terms-explained-%3A">Prerequisites and difficult terms explained :</h4>

<p>Before starting actual implementation, let's take a minute to understand few terms which are little tricky. I am very sure if any of you have dived into SSM automation for first time, you came across these and felt little overwhelmed.</p>

<p>When you set up the <code>AWS-UpdateLinuxAmi</code> automation, the form in AWS console asks you to give certain <a href="https://eu-west-2.console.aws.amazon.com/systems-manager/documents/AWS-UpdateLinuxAmi/parameters?region=eu-west-2"><code>parameters</code></a>(details of the setup)</p>

<p>The 2 parameters <code>IamInstanceProfileName</code> and <code>AutomationAssumeRole</code> are tricky to understand.</p>

<ul>
<li>IamInstanceProfileName :</li>
</ul>

<p>It's also referred as <code>ManagedInstanceProfile</code>. When AWS SSM runs the automation execution <code>AWS-UpdateLinuxAmi</code>, SSM needs to take certain actions in EC2 service. These are launching an instance from an existing source AMI, creating a new AMI from updated instance state and terminating the temparary instance etc.</p>

<p>For this purpose you create a new <code>IAM Role</code> (Identity Access Manamegement Role). The <code>IamInstanceProfileName</code> is nothing but the name of this created <code>IAM Role</code>.</p>

<ul>
<li>AutomationServiceRole :</li>
</ul>

<p>When SSM runs the automation execution <code>AWS-UpdateLinuxAmi</code>, SSM needs to assume the IAM role which we created for <code>IamInstanceProfileName</code> above, pass it as allowed so that it can function with the respective policies it's attached with.</p>

<p>For this purpose you create second a new <code>IAM Role</code> (Identity Access Manamegement Role). The <code>AutomationServiceRole</code> is nothing but the arn(Amazon Resource Name) of this created <code>IAM Role</code>.</p>

<ul>
<li>Trust Relationships :</li>
</ul>

<p>When you create both these roles mentioned above(We will dived in detail below), we need to update their <code>Trust Relationships</code>. With IAM roles, you can establish mutual trust relationships between your trusting account. In short, the trusting account owns the resource to be accessed and the trusted account contains the users who need access to the resource.</p>

<h4 id="creating-required-iam-roles-%3A">Creating required IAM roles :</h4>

<h5 id="step-1-%3A-create-iam-role-for-%2Aiaminstanceprofilename%2A-%3A">Step 1 : Create IAM Role for <em>IamInstanceProfileName</em> :</h5>

<pre><code>- Login to AWS console and go to `IAM` service. 
- Go to Roles listing and click on `Create Role`
- Keep type selected as `AWS Service`
- Below in `Choose the service that will use this role` section select `EC2`
- Click on `Next : Permissions` button on bottom right
- It will bring the page to attach permission policies
- Select `AmazonEC2RoleforSSM` policy
- Click on `Next : Tags` button on bottom right
- Add tags if you want or skip to next step by clicking `Next : Review` button on bottom right
- It will bring page to add role details
- Add a `Role name` as `ManagedInstanceProfileForSSM`
- Click on `Create Role`
</code></pre>

<h5 id="step-2-%3A-create-iam-role-for-%2Aautomationservicerole%2A-%3A">Step 2 : Create IAM Role for <em>AutomationServiceRole</em> :</h5>

<pre><code>- Login to AWS console and go to `IAM` service. 
- Go to Roles listing and click on `Create Role`
- Keep type selected as `AWS Service`
- Below in `Choose the service that will use this role` section select `EC2`
- Click on `Next : Permissions` button on bottom right
- It will bring the page to attach permission policies
- Select `AmazonSSMAutomationRole` policy
- Click on `Next : Tags` button on bottom right
- Add tags if you want or skip to next step by clicking `Next : Review` button on bottom right
- It will bring page to add role details
- Add a `Role name` as `AutomationServiceRole`
- Click on `Create Role`
</code></pre>

<h5 id="step-3-%3A-get-the-arn-string-of-%2Amanagedinstanceprofileforssm%2A-%3A">Step 3 : Get the arn string of <em>ManagedInstanceProfileForSSM</em> :</h5>

<p>We need to associate the first cerated IAM role <code>IamInstanceProfileName</code> to pass in this role.</p>

<pre><code>- Go to Roles listing and select `ManagedInstanceProfileForSSM`
- It will show the details of this role
- Copy the `arn` of this role 
- The arn will be in a format `arn:aws:iam::{IAM_USER_ID}:role/ManagedInstanceProfileForSSM`
- Keep this arn string somewhere as we will need it in next steps
</code></pre>

<h5 id="step-4-%3A-create-policy-to-pass-the-above-arn-into-second-role-%3A">Step 4 : Create policy to pass the above arn into second role :</h5>

<pre><code>- Login to AWS console and go to `IAM` service. 
- Go to `Policies` listing and click on `Create Ppolicy`
- It will show you visual editor and JSON tabs
- Click on `JSON` tab and paste following policy json
</code></pre>

<pre><code class="json">{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "VisualEditor0",
            "Effect": "Allow",
            "Action": "iam:PassRole",
            "Resource": "arn:aws:iam::{IAM_USER_ID}:role/ManagedInstanceProfileForSSM"
        }
    ]
}
</code></pre>

<pre><code>- Make sure you replace the resource arn in this policy json with the one you copied just few steps back
- Click on `Review Policy` button on bottom right 
- Give policy name as `PassPolicyForIamInstanceProfileRole` and create the policy
</code></pre>

<h5 id="step-5-%3A-attach-policy-to-pass-the-above-arn-into-second-role-%3A">Step 5 : Attach policy to pass the above arn into second role :</h5>

<pre><code>- Login to AWS console and go to `IAM` service.
- Go to Roles listing and select `AutomationServiceRole`
- Click on `Attach Policies` and attach `PassPolicyForIamInstanceProfileRole` policy
</code></pre>

<h5 id="step-5-%3A-update-trust-relationships-%3A">Step 5 : Update trust relationships :</h5>

<pre><code>- Login to AWS console and go to `IAM` service.
- Go to Roles listing and select `ManagedInstanceProfileForSSM`
- Go go `Trust Relationships` tab and click on `Edit trust relationship`
- Add following json and click on `Update trust relationship` in bottom right
</code></pre>

<pre><code class="json">{
    "Version": "2012-10-17",
    "Statement": [
        {
        "Effect": "Allow",
        "Principal": {
            "Service": [
            "ec2.amazonaws.com",
            "ssm.amazonaws.com"
            ]
        },
        "Action": "sts:AssumeRole"
        }
    ]
}
</code></pre>

<p>Hush!! Now the confusing part is DONE! We have few lats simple steps to complete.</p>

<h4 id="creating-script-of-commands-to-run-%3A">Creating script of commands to run :</h4>

<p>We need to create a script of commands which will run on the instance. This script needs to be stored on web and we just pass url of this script while configuring the automation execution.</p>

<p>For this, we will simply create an s3 bucket and store file in there instead.</p>

<pre><code>- Login to AWS console and go to `S3` service.
- Click on `Create Bucket`
- Give bucket a name and click on `Create`
- Create a script file on your local machine with name `ssm-automation.sh` and add below contents in it
</code></pre>

<pre><code class="bash">#!/bin/bash

# This script installs latex on the instance
# Feel free to change this as per your needs
sudo apt-get update
sudo apt-get install texlive-latex-base -y --allow-unauthenticated
</code></pre>

<pre><code>- Now upload this script file from your local machine to the new s3 bucket
- Once upload is completed, click on the file and click on `Make Public` so that it's publically accessible
- Copy its public url and save it somewhere as we will need it in next step
</code></pre>

<h4 id="the-moment-you-have-been-waiting-for-%3A">The moment you have been waiting for :</h4>

<p>Now its time to set up the final automation execution.</p>

<pre><code>- Login to AWS console and go to `Systems Manager` service.
- Click on `Automation`
- Click on `Execute Automation`
- Choose document page select `AWS-UpdateLinuxAmi`
</code></pre>

<p><img src="/images/aws-ssm-iam/select.png" alt="alt text" /></p>

<pre><code>- Click on `Next` on bottom right
- Add `SourceAmiId` as the AMI you want to update
- Add `IamInstanceProfileName` with value `ManagedInstanceProfileForSSM`
- In `AutomationAssumeRole` select `AutomationServiceRole`
- Update `TargetAmiName` with one you want
- Select instance type based on memory and space you need for your command executions
- Keep `SubnetId` blank if you do not want to launch the temparary instance in a specific VPC subnet
- Keep `PreUpdateScript` to `none`
- Update `PostUpdateScript` with public s3 script url
- Keep `IncludePackages` and `ExcludePackages` to `none`
- And finally... Click on `Execute`
</code></pre>

<p><img src="/images/aws-ssm-iam/setup.png" alt="alt text1" /></p>

<p>You will see progress of the automation with each step and it's details.</p>

<p><img src="/images/aws-ssm-iam/execution.png" alt="alt text" /></p>

<h4 id="some-suggestions-on-best-practices-%3A">Some suggestions on best practices :</h4>

<ol>
<li>If you have AWS instances setup in a custom VPC to comply with security regulations, make sure you select the VPC subnet ID so that the temparary instance will launch in that VPC. If not specified it launches instance in Default VPC</li>
<li>The script of commands you put in s3 should not contain any sensitive information. Instead, store it in AWS System manager parameter store. You need to make sure your EC2 instance profile has policy to access the parameter store.</li>
<li>Know what your commands do to guess how much memory and space and set the instance type accordingly while configuration automation execution.</li>
<li>Once you are comfortable with above basic setup, go ahead and study the execution document json. You can do lot of customization and actions like what happens if a step fails etc.</li>
</ol>

<h4 id="why-so-much-pain-%3A">Why so much pain :</h4>

<p>You might be thinking why go through so much pain of setup when manually you can do it in 15-20 minutes? Don't worry as it's a one time setup time. Next time all you need to do it update the AMI script in s3 and run the execution. Grab your coffee and relax when AWS creates a new update AMI version for you!</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[AWS Load Balancer stickiness and load distribution]]></title>
            <link href="https://techsemicolon.github.io/blog/2019/04/19/aws-load-balancer-stickiness-load-distribution/"/>
            <updated>2019-04-19T00:00:00+00:00</updated>
            <id>https://techsemicolon.github.io/blog/2019/04/19/aws-load-balancer-stickiness-load-distribution/</id>
            <content type="html"><![CDATA[<p>AWS load balancing is an interesting cloud service which automatically distributes incoming application traffic across multiple available target servers, such as Amazon EC2 instances, containers, IP addresses, and Lambda functions. It helps the infrastructure to have high availability, automatic scaling and as a result makes application more fault tolerant.</p>

<ul>
<li>Quick question :</li>
</ul>

<p>As per the concept of AWS load balancer with autoscaling, if the traffic is increased which current servers can not handle, new server is launched automatically and added under the load balancer so that the traffic is distributed across available target servers.</p>

<p>Let's say for an example :</p>

<p>We have an Application load balancer(ALB) which has minimum 2 servers, maximum it can autoscale to 10 servers. Each server can serve user traffic for 50 users.</p>

<p>The server has autoscaling policy based on <code>CPUUtilization</code>, when server goes above 75% for CPUUtilization metrix, autoscaling shoul spin up new instance.</p>

<p>At 8AM there are 50 users, the traffic is distributed across 2 servers and everything is normal.
AT 10AM there are 95 user and the CPUUtilization is greater than 75% threashold, a new server spins up.</p>

<p>Now, at 10.15AM can you be sure that the traffic load is distributed evenly by the autoscaling?</p>

<ul>
<li>Let's find out :</li>
</ul>

<ol>
<li>Server spin up time :</li>
</ol>

<p>Server spin up time, also called as instance warmup time, is the duration in which server spin up is initiated and server is ready to server requests. This depends upon the configuration scripts and start up commands which are run when server is spinning up.</p>

<p>The instances use a configuration script to install and configure software before the instance is put into service. As a result, it takes around two or three minutes from the time the instance launches until it comes in service. This is not entirely in our hands and AWS internal infrastructure also contributes to this time. The actual time depends on several factors, such as the size of the instance and whether there are startup scripts to complete.</p>

<p>However, this is important to know how much time your server takes on an average to be ready. Because if your server takes on an average 15 minutes to spin up, all the increased traffic will still served by old overwhelmed servers for that 15 minute period.</p>

<p>AWS uses <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html">cooldown period</a> setting for simple autoscaling policy to handle the startup time.</p>

<ol start="2">
<li>Sticky session or stickyness of the load balancer :</li>
</ol>

<p><a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-target-groups.html#sticky-sessions">Sticky session</a> or stickyness of load balancer the setting to route the traffic incoming requests for a particular session to the same target server that serviced the initial request for that session. In short, under load balancer having 3 servers S1, S2 and S3, if User A's first request was served by S2 server, his subsqeuent requests will be also served by S2 server until the request stickyness is expired or disabled or deliberatly updated(by sending differnet AWSALB cookie in request)</p>

<p>More interestingly, the load balancer will always distribute traffic in a round robin algorithm. This is done with each request without stickiness and done on each session with stickiness.</p>

<p>As soon as a new instance is spun up and joins the group, it will not immediately get all the traffic. but it will join in the pool of round robin distribution of incoming traffic.</p>

<p>With stickiness setting enabled, existing sessions <code>will still have all requests routed to existing instances</code>. Only <code>new</code> sessions may hit the new instance. Being round robin, new sessions may also get routed to the existing instances.</p>

<p>Without stickiness, request from existing users will immediately get routed to the new instance. Hence it's safe to say that how quickly traffic load will be equilized and distributed across all available instances will depend on stickiness.</p>

<p>Sticky session comes up with a setting of expiration. You can specify a time from 1 second to 7 days. This setting is really important and you should definitely pay attension to the value you are setting. If this value is very large, spinning up new instances when autoscaling kicks in will not be useful as existing traffic is still stick with old servers.</p>

<p>Also a key point to note that for sticky session expiration Period, type the cookie expiration period, in seconds. If you do not specify an expiration period, the sticky session lasts for the duration of the browser session.</p>

<ul>
<li>Know if you need sticky sessions :</li>
</ul>

<p>Even if the sticky session setting is a good choice, it's for the applications which maintain the session state on service target instance. For example, a php web server maintaining sessions in local filesystem of EC2 instance. In that case if user request is served by other EC2 instance, then user will be logged out die to that session not being present there.</p>

<p>However, if your session state is managed by a separate service like RDS, Redis, Elasticache etc which is independent of which target server is serving your request, you probably do not even need sticky sessions.</p>

<ul>
<li>The bottom line :</li>
</ul>

<p>Test and find the best settings as per your application when setting up auto-scaling policies. Because, if your server is not ready quickly when the application needs it for serving increased traffic, it's going to affect your application performance specially during peak hours.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Laravel use secure SSL connection while using AWS RDS]]></title>
            <link href="https://techsemicolon.github.io/blog/2019/04/10/laravel-rds-ssl-encryption-in-transit/"/>
            <updated>2019-04-10T00:00:00+00:00</updated>
            <id>https://techsemicolon.github.io/blog/2019/04/10/laravel-rds-ssl-encryption-in-transit/</id>
            <content type="html"><![CDATA[<p>Amazon Relational Database Service Amazon RDS is a cloud based web service that makes things easier to set up, operate, and scale a relational databases on the cloud. It has become one of the popular choices when setting up laravel database infrastructure.</p>

<ul>
<li>Quick question :</li>
</ul>

<p>If you are using AWS RDS in your laravel application, is your connection encrypted in transit? Or so ask other way around, is your laravel application connecting to AWS RDS using a secure SSL connection?</p>

<p>If you think that RDS comes up with secure encryption in transit, you are right, it implements SSL. However, is it turned on somehow by default or is it there when we use it directly? Not really.. I had a perception that my laravel app is secured in transit by SSL encryption until I found out its not.</p>

<ul>
<li>Let's find out :</li>
</ul>

<p>Connect to the environment/server/container where laravel is hosted and run tinker :</p>

<pre><code class="bash">php artisan tinker
</code></pre>

<p>Once, the tinker prompt is open, run following :</p>

<pre><code class="bash">&gt;&gt;&gt; DB::select("SHOW STATUS LIKE 'Ssl_cipher'")
</code></pre>

<p>If it gives output like following :</p>

<pre><code class="bash">=&gt; [
    {
        +"Variable_name": "Ssl_cipher",
        +"Value": "DHE-RSA-AES128-SHA",
    },
]
</code></pre>

<p>Then laravel application is connecting to AWS RDS via a secure SSL connection.</p>

<p>However, if the output is like this  :</p>

<pre><code class="bash">=&gt; [
    {
        +"Variable_name": "Ssl_cipher",
        +"Value": "",
    },
]
</code></pre>

<p>Then the connection is not sure. There are number of variables which you can help us get more information about the SSL connection paramaters. We checked <code>Ssl_cipher</code> above, you can also check <code>Ssl_version</code> which might give you blank or something like <code>TLSv1</code> if SSL is working.</p>

<p>To get all information about SSL connection run following in tinker prompt :</p>

<pre><code class="bash">&gt;&gt;&gt; DB::select("SHOW STATUS LIKE '%Ssl%'")
</code></pre>

<ul>
<li>Next steps to secure the connection :</li>
</ul>

<p>If you found out that the laravel application connection is not using SSL while connecting to AWS RDS, you can follow below steps to enable the same.</p>

<p>Firstly, let us understand how it works. When you connect to AWS RDS normally via mysql cli, you do :</p>

<pre><code class="bash">mysql -h myinstance.c9akciq32.rds-us-east-1.amazonaws.com -u username -p
</code></pre>

<p>You can pass SSL certificate using <code>--ssl-ca</code> option in above command like below :</p>

<pre><code class="bash">mysql -h myinstance.c9akciq32.rds-us-east-1.amazonaws.com --ssl-ca=/path/to/certificate-authority-file.pem -u username -p
</code></pre>

<p>Optionally, you can pass <code>-ssl-mode</code> and <code>--ssl-verify-server-cert</code>. For more details about this please refer mysql's official <a href="https://dev.mysql.com/doc/refman/5.7/en/encrypted-connection-options.html">documentation</a>.</p>

<p>Now let's get back to the original problem which we are here to solve. How we are going to do this in Laravel?</p>

<p>Step 1 : Downloading the <code>certificate authority file</code>. AWS RDS has a commonly published pem file called <code>rds-combined-ca-bundle.pem</code> which you can download directly from <a href="https://s3.amazonaws.com/rds-downloads/rds-combined-ca-bundle.pem">here</a>. It is an officially published pem file which will work in all default RDS SSL connections.</p>

<p>Step 2 : Save the downloaded file from step 1 inside a new directory called <code>RDSCerts</code> inside laravel root. Quick note that in this step itself, I would add this inside gitignore because there is no need to add pem and cert files inside the version control.</p>

<p>Step 3 : Laravel's database configurations are inside <code>config/database.php</code> file. It already has a <code>mysql</code> section. Let's not change that, lets copy that entirely into a new configuration section called <code>mysql_ssl</code> where we will also add the certification authority file in options like below :</p>

<pre><code class="php">'mysql_ssl' =&gt; [
    'driver' =&gt; 'mysql',
    'host' =&gt; env('DB_HOST', '127.0.0.1'),
    'port' =&gt; env('DB_PORT', '3306'),
    'database' =&gt; env('DB_DATABASE', 'forge'),
    'username' =&gt; env('DB_USERNAME', 'forge'),
    'password' =&gt; env('DB_PASSWORD', ''),
    'unix_socket' =&gt; env('DB_SOCKET', ''),
    'charset' =&gt; 'utf8mb4',
    'collation' =&gt; 'utf8mb4_unicode_ci',
    'prefix' =&gt; '',
    'prefix_indexes' =&gt; true,
    'strict' =&gt; false,
    'engine' =&gt; null,
    'options' =&gt; [    
        PDO::MYSQL_ATTR_SSL_CA =&gt; base_path('RDSCerts/rds-combined-ca-bundle.pem')
    ],
],
</code></pre>

<p>Important note, You might be thinking that when we need to pass <code>--ssl-verify-server-cert</code> option somehow from laravel's configuration as well. Don't worry it's enabled by default. If you want to disable it then you can pass <code>PDO::MYSQL_ATTR_SSL_VERIFY_SERVER_CERT = false</code> which I would not suggest.</p>

<p>There are more options about SSL which you can check in the official PDO <a href="https://www.php.net/manual/en/ref.pdo-mysql.php">documentation</a>.</p>

<p>Once you follow above 3 steps, you should be good to go. Cross check by running <code>DB::select("SHOW STATUS LIKE '%Ssl%'")</code> in tinker as we did earlier in this article. You should see ciphers and ssl version mentioned in the connection.</p>
]]></content>
        </entry>
    </feed>